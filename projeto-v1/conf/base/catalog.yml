# Here you can define all your datasets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html
bank_data:
  type: pandas.CSVDataset
  filepath: data/01_raw/bank-additional-full.csv
  load_args:
    sep: ";"
    encoding: "utf-8-sig"

## ------------------ ingestion pipe ------------------------
ingested_data:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/ingested_data.csv

## ------------------ data_expectations pipe ----------------
validated_data:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/validated_data.csv


## ------------------ feature_engineering pipe ------------------------
data_engineered:
  type: pandas.CSVDataset
  filepath: data/03_primary/data_engineered.csv
  
## ------------------ Split data pipe ---------------------------------
X_train_data:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_train.csv

y_train_data:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_train.csv

X_test_data:
  type: pandas.CSVDataset
  filepath: data/05_model_input/X_test.csv

y_test_data:
  type: pandas.CSVDataset
  filepath: data/05_model_input/y_test.csv 